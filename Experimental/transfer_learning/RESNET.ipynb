{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow        as tf\n",
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import copy\n",
    "\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = 'D:/imagenet_object_localization/ILSVRC/Data/CLS-LOC/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writer = tf.summary.FileWriter('./log_tmp/', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_dict(file_path):\n",
    "    key_to_label = {}\n",
    "    keys         = []\n",
    "    \n",
    "    pos            = 0\n",
    "    key_length     = 9\n",
    "    newline_length = 1\n",
    "    \n",
    "    with open(file_path) as file:\n",
    "        for index in range(1000):\n",
    "            key = file.read(key_length)\n",
    "        \n",
    "            file.seek(pos + key_length + newline_length)\n",
    "            \n",
    "            label = file.readline()\n",
    "            \n",
    "            file.seek(pos + key_length + newline_length + len(label))\n",
    "            \n",
    "            pos = file.tell()\n",
    "            \n",
    "            label             = label.replace(\"\\n\", \"\")\n",
    "            key_to_label[key] = label\n",
    "            \n",
    "            keys.append(key)\n",
    "\n",
    "    return keys, key_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(filePath, training=True):\n",
    "    image = cv2.imread(filePath)\n",
    "    \n",
    "    if training:\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_set(folder_path, size=-1):\n",
    "    training_examples = []\n",
    "    count = 0\n",
    "    for image_set in os.listdir(folder_path):\n",
    "        for image in os.listdir(folder_path + image_set):\n",
    "            example = { 'label' : image_set, 'path' : folder_path + image_set + '/' + image}\n",
    "            training_examples.append(example)\n",
    "            count += 1\n",
    "            \n",
    "        if size != -1 and count > size:\n",
    "             break\n",
    "            \n",
    "    return training_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_batch(training_examples, batch, batch_size, onehot_encoded, label_encoder):\n",
    "    start = batch * batch_size\n",
    "    end   = (batch + 1) * batch_size\n",
    "    \n",
    "    labels = []\n",
    "    images = []\n",
    "    \n",
    "    for index in range(start, end):\n",
    "        example = training_examples[index]\n",
    "        image = cv2.imread(example['path'])\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        \n",
    "        onehot_label = onehot_encoded[label_encoder.transform([example['label']])[0]]\n",
    "        \n",
    "        labels.append(onehot_label)\n",
    "        images.append(image       )\n",
    "        \n",
    "    return labels, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_model(model_input):\n",
    "    output = tf.layers.conv2d(model_input, filters=64, kernel_size=(7,7), strides=(2,2))\n",
    "    output = tf.layers.batch_normalization(output)\n",
    "    output = tf.nn.relu(output)\n",
    "    output = tf.layers.max_pooling2d(output, pool_size=(3,3) ,strides=(2,2))\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_connection(input_layer, filters, layer):\n",
    "    x      = tf.layers.conv2d             (input_layer, filters=filters, kernel_size=(3, 3), padding='SAME', name=\"conv1_\" + layer)\n",
    "    output = tf.layers.batch_normalization(x, name=\"batch1_\" + layer)\n",
    "    output = tf.nn.relu                   (output, name=\"relu1_\" + layer)\n",
    "    \n",
    "    output = tf.layers.conv2d             (output     , filters=filters, kernel_size=(3, 3), padding='SAME', name=\"conv2_\" + layer)\n",
    "    output = tf.layers.batch_normalization(output, name=\"batch2_\" + layer)\n",
    "    output = tf.nn.relu                   (output, name=\"relu2_\" + layer)\n",
    "    \n",
    "    skip   = tf.layers.conv2d(x     ,filters=filters , kernel_size=(1, 1), strides=(1,1), padding='SAME', activation=tf.nn.relu, name=\"convskip_\" + layer)\n",
    "    skip   = tf.nn.relu(skip, name=\"reluskip_\" + layer)\n",
    "    \n",
    "    return tf.keras.layers.concatenate([output, skip])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet_model(num_categories = 1000, gpu=False):\n",
    "    model_input = tf.placeholder(dtype = tf.float32, shape = (None, 224, 224, 3), name = 'model_input')\n",
    "    is_training = tf.placeholder(dtype = tf.bool,                                 name = 'is_training')\n",
    "    \n",
    "    device_string = \"gpu:0\" if gpu else \"cpu:0\"\n",
    "    \n",
    "    with tf.device(device_string):\n",
    "        output = start_model(model_input)\n",
    "        \n",
    "        #FIRST SET OF 64 FILTER CONVOLUTIONS\n",
    "        output = skip_connection(output, 64,  \"1a\")\n",
    "        output = skip_connection(output, 64,  \"1b\")\n",
    "        output = skip_connection(output, 64,  \"1c\")\n",
    "        output = skip_connection(output, 64,  \"1d\")\n",
    "        output = skip_connection(output, 64,  \"1e\")\n",
    "        output = skip_connection(output, 64,  \"1f\")\n",
    "        \n",
    "        #SECOND SET OF 128 FILTER CONVOLUTIONS\n",
    "        output = skip_connection(output, 224, \"2a\")\n",
    "        output = skip_connection(output, 224, \"2b\")\n",
    "        output = skip_connection(output, 224, \"2c\")\n",
    "        output = skip_connection(output, 224, \"2d\")\n",
    "        output = skip_connection(output, 224, \"2e\")\n",
    "        output = skip_connection(output, 224, \"2f\")\n",
    "        output = skip_connection(output, 224, \"2g\")\n",
    "        output = skip_connection(output, 224, \"2h\")\n",
    "        \n",
    "        #THIRD SET OF 256 FILTER CONVOLUTIONS\n",
    "        output = skip_connection(output, 224, \"3a\")\n",
    "        output = skip_connection(output, 224, \"3b\")\n",
    "        output = skip_connection(output, 224, \"3c\")\n",
    "        output = skip_connection(output, 224, \"3d\")\n",
    "        output = skip_connection(output, 224, \"3e\")\n",
    "        output = skip_connection(output, 224, \"3f\")\n",
    "        output = skip_connection(output, 224, \"3g\")\n",
    "        output = skip_connection(output, 224, \"3h\")\n",
    "        output = skip_connection(output, 224, \"3i\")\n",
    "        output = skip_connection(output, 224, \"3j\")\n",
    "        output = skip_connection(output, 224, \"3k\")\n",
    "        output = skip_connection(output, 224, \"3l\")\n",
    "        \n",
    "        #FOURTH SET OF 512 FILTER CONVOLUTIONS\n",
    "        output = skip_connection(output, 224, \"4a\")\n",
    "        output = skip_connection(output, 224, \"4b\")\n",
    "        output = skip_connection(output, 224, \"4c\")\n",
    "        output = skip_connection(output, 224, \"4d\")\n",
    "        output = skip_connection(output, 224, \"4e\")\n",
    "        output = skip_connection(output, 224, \"4f\")\n",
    "        \n",
    "        #AVERAGE POOL\n",
    "        output = tf.layers.average_pooling2d(output, pool_size=(2,2), strides=(2,2), name=\"avg_pool\")\n",
    "        \n",
    "        #FLATTEN AND PERFORM SOFTMAX\n",
    "        output = tf.layers.flatten(output)\n",
    "        output = tf.layers.dense  (output, num_categories)\n",
    "        \n",
    "        #IF WE'RE TRAINING, ALLOW COST LAYER TO PERFORM SOFTMAX, ELSE IF INFERING PEROFRM IT HERE\n",
    "        output = tf.cond(is_training, lambda: output, lambda: tf.nn.softmax(output))\n",
    "        \n",
    "        output = tf.identity(output, name=\"final_output\")\n",
    "    \n",
    "    return output, model_input, is_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_encoder(keys):\n",
    "    label_encoder   = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(keys)\n",
    "    \n",
    "    onehot_encoder  = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded  = onehot_encoder.fit_transform(integer_encoded)\n",
    "    \n",
    "    return label_encoder, onehot_encoded\n",
    "\n",
    "#label_encoder, onehot_encoded = get_key_encoder(keys)\n",
    "\n",
    "#print(onehot_encoded[label_encoder.transform(['n01484850'])[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = get_label_dict(\"D:/imagenet_object_localization/LOC_synset_mapping/LOC_synset_mapping.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[326592,1000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node dense/kernel/Initializer/random_uniform/RandomUniform (defined at <ipython-input-10-483599925f48>:55)  = RandomUniform[T=DT_INT32, _class=[\"loc:@dense/kernel/Assign\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense/kernel/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'dense/kernel/Initializer/random_uniform/RandomUniform', defined at:\n  File \"c:\\program files (x86)\\microsoft visual studio\\shared\\anaconda3_64\\Lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\program files (x86)\\microsoft visual studio\\shared\\anaconda3_64\\Lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\program files (x86)\\microsoft visual studio\\shared\\anaconda3_64\\Lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"c:\\program files (x86)\\microsoft visual studio\\shared\\anaconda3_64\\Lib\\asyncio\\base_events.py\", line 1426, in _run_once\n    handle._run()\n  File \"c:\\program files (x86)\\microsoft visual studio\\shared\\anaconda3_64\\Lib\\asyncio\\events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-20-e64003ff5f40>\", line 5, in <module>\n    model, model_input, is_training = get_resnet_model(gpu=True)\n  File \"<ipython-input-10-483599925f48>\", line 55, in get_resnet_model\n    output = tf.layers.dense  (output, num_categories)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\layers\\core.py\", line 184, in dense\n    return layer.apply(inputs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 817, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 374, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 746, in __call__\n    self.build(input_shapes)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py\", line 944, in build\n    trainable=True)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 288, in add_weight\n    getter=vs.get_variable)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 609, in add_weight\n    aggregation=aggregation)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\training\\checkpointable\\base.py\", line 639, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1487, in get_variable\n    aggregation=aggregation)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1237, in get_variable\n    aggregation=aggregation)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 540, in get_variable\n    aggregation=aggregation)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 492, in _true_getter\n    aggregation=aggregation)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 922, in _get_single_variable\n    aggregation=aggregation)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 183, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 146, in _variable_v1_call\n    aggregation=aggregation)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 125, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2444, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 187, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 1329, in __init__\n    constraint=constraint)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 1437, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 896, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py\", line 486, in __call__\n    shape, -limit, limit, dtype, seed=self.seed)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py\", line 243, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_random_ops.py\", line 772, in random_uniform\n    name=name)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[326592,1000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node dense/kernel/Initializer/random_uniform/RandomUniform (defined at <ipython-input-10-483599925f48>:55)  = RandomUniform[T=DT_INT32, _class=[\"loc:@dense/kernel/Assign\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense/kernel/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[326592,1000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node dense/kernel/Initializer/random_uniform/RandomUniform}} = RandomUniform[T=DT_INT32, _class=[\"loc:@dense/kernel/Assign\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense/kernel/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-e64003ff5f40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mskip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m \u001b[0mmodel_input\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mrandom_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_training\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[326592,1000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node dense/kernel/Initializer/random_uniform/RandomUniform (defined at <ipython-input-10-483599925f48>:55)  = RandomUniform[T=DT_INT32, _class=[\"loc:@dense/kernel/Assign\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense/kernel/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'dense/kernel/Initializer/random_uniform/RandomUniform', defined at:\n  File \"c:\\program files (x86)\\microsoft visual studio\\shared\\anaconda3_64\\Lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\program files (x86)\\microsoft visual studio\\shared\\anaconda3_64\\Lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\program files (x86)\\microsoft visual studio\\shared\\anaconda3_64\\Lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"c:\\program files (x86)\\microsoft visual studio\\shared\\anaconda3_64\\Lib\\asyncio\\base_events.py\", line 1426, in _run_once\n    handle._run()\n  File \"c:\\program files (x86)\\microsoft visual studio\\shared\\anaconda3_64\\Lib\\asyncio\\events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-20-e64003ff5f40>\", line 5, in <module>\n    model, model_input, is_training = get_resnet_model(gpu=True)\n  File \"<ipython-input-10-483599925f48>\", line 55, in get_resnet_model\n    output = tf.layers.dense  (output, num_categories)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\layers\\core.py\", line 184, in dense\n    return layer.apply(inputs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 817, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 374, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 746, in __call__\n    self.build(input_shapes)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py\", line 944, in build\n    trainable=True)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 288, in add_weight\n    getter=vs.get_variable)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 609, in add_weight\n    aggregation=aggregation)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\training\\checkpointable\\base.py\", line 639, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1487, in get_variable\n    aggregation=aggregation)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1237, in get_variable\n    aggregation=aggregation)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 540, in get_variable\n    aggregation=aggregation)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 492, in _true_getter\n    aggregation=aggregation)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 922, in _get_single_variable\n    aggregation=aggregation)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 183, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 146, in _variable_v1_call\n    aggregation=aggregation)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 125, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2444, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 187, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 1329, in __init__\n    constraint=constraint)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 1437, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 896, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py\", line 486, in __call__\n    shape, -limit, limit, dtype, seed=self.seed)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py\", line 243, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_random_ops.py\", line 772, in random_uniform\n    name=name)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[326592,1000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node dense/kernel/Initializer/random_uniform/RandomUniform (defined at <ipython-input-10-483599925f48>:55)  = RandomUniform[T=DT_INT32, _class=[\"loc:@dense/kernel/Assign\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense/kernel/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "ops.reset_default_graph()\n",
    "\n",
    "random_input= np.random.rand(256, 224, 224, 3)\n",
    "\n",
    "model, model_input, is_training = get_resnet_model(gpu=True)\n",
    "\n",
    "init  = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    skip = sess.run([model], feed_dict = { model_input : random_input, is_training : True})\n",
    "    \n",
    "print(skip[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys, key_dict = get_label_dict('D:/imagenet_object_localization/LOC_synset_mapping/LOC_synset_mapping.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_resnet(training_examples, keys, learning_rate=1e-5, num_epochs=5, batch_size=16, epoch_start=0, restore_path=\"\"):\n",
    "    ops.reset_default_graph()\n",
    "    \n",
    "    m                             = len(training_examples)\n",
    "    label_encoder, onehot_encoded = get_key_encoder(keys)\n",
    "    \n",
    "    labels = tf.placeholder(dtype = tf.float32, shape = (None, 1000), name = 'labels')\n",
    "    \n",
    "    model, model_input, is_training = get_resnet_model(gpu=True)\n",
    "    \n",
    "    with tf.device('gpu:0'):\n",
    "        cost      = tf.losses.softmax_cross_entropy(onehot_labels=labels, logits=model)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "        \n",
    "    saver = tf.train.Saver()\n",
    "    init  = tf.global_variables_initializer()\n",
    "    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "    sess.run(init)\n",
    "    \n",
    "    if os.path.exists(restore_path) == True:\n",
    "        saver = tf.train.import_meta_graph(restore_path + 'resnet.ckpt.meta')\n",
    "        saver.restore(sess, restore_path + 'resnet.ckpt')\n",
    "        \n",
    "        \n",
    "    tf.train.write_graph(sess.graph.as_graph_def(), './train/resnet_model', 'resnet.pbtxt', True)\n",
    "    \n",
    "    for epoch in range(epoch_start, epoch_start + num_epochs):\n",
    "        epoch_cost  = 0\n",
    "        num_batches = (int)(m / batch_size)\n",
    "    \n",
    "        shuffle(training_examples)\n",
    "        \n",
    "        for batch in range(num_batches):\n",
    "            #l, i           = get_training_batch(training_examples, batch, batch_size, onehot_encoded, label_encoder)\n",
    "            l = np.random.rand(16, 1000)\n",
    "            i = np.random.rand(16, 224, 224, 3)\n",
    "            \n",
    "            \n",
    "            \n",
    "            _, batch_cost  = sess.run([optimizer, cost], feed_dict = { model_input : i, labels : l, is_training : True})\n",
    "            epoch_cost    += batch_cost / num_batches\n",
    "            \n",
    "            print(str(batch) + ' out of ' + str(num_batches))\n",
    "                    \n",
    "        if epoch % 10 == 0:\n",
    "            saver.save(sess, './train_' + str(epoch) + '/resnet.ckpt')\n",
    "            print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            print ()\n",
    "            print (\"---------------------------------------------\")\n",
    "            print ()\n",
    "        \n",
    "    print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "    print ()\n",
    "    print (\"---------------------------------------------\")\n",
    "    print ()\n",
    "    saver.save(sess, './train_final/restnet.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys, key_dict = get_label_dict('D:/imagenet_object_localization/LOC_synset_mapping/LOC_synset_mapping.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = get_training_set(training_path, size=1000)\n",
    "\n",
    "shuffle(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1300"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[16,224,54,54] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node conv2_2a/Conv2D (defined at <ipython-input-9-3da0f65c3867>:6)  = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](relu1_2a, conv2_2a/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node softmax_cross_entropy_loss/value/_11}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_9603_softmax_cross_entropy_loss/value\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'conv2_2a/Conv2D', defined at:\n  File \"c:\\program files (x86)\\microsoft visual studio\\shared\\anaconda3_64\\Lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\program files (x86)\\microsoft visual studio\\shared\\anaconda3_64\\Lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\program files (x86)\\microsoft visual studio\\shared\\anaconda3_64\\Lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"c:\\program files (x86)\\microsoft visual studio\\shared\\anaconda3_64\\Lib\\asyncio\\base_events.py\", line 1426, in _run_once\n    handle._run()\n  File \"c:\\program files (x86)\\microsoft visual studio\\shared\\anaconda3_64\\Lib\\asyncio\\events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-257b7e4de8a3>\", line 1, in <module>\n    train_resnet(training_set, keys)\n  File \"<ipython-input-12-d01846391362>\", line 9, in train_resnet\n    model, model_input, is_training = get_resnet_model(gpu=True)\n  File \"<ipython-input-10-483599925f48>\", line 19, in get_resnet_model\n    output = skip_connection(output, 224, \"2a\")\n  File \"<ipython-input-9-3da0f65c3867>\", line 6, in skip_connection\n    output = tf.layers.conv2d             (output     , filters=filters, kernel_size=(3, 3), padding='SAME', name=\"conv2_\" + layer)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\layers\\convolutional.py\", line 417, in conv2d\n    return layer.apply(inputs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 817, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 374, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 757, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\", line 194, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 868, in __call__\n    return self.conv_op(inp, filter)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 520, in __call__\n    return self.call(inp, filter)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 204, in __call__\n    name=self.name)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1044, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[16,224,54,54] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node conv2_2a/Conv2D (defined at <ipython-input-9-3da0f65c3867>:6)  = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](relu1_2a, conv2_2a/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node softmax_cross_entropy_loss/value/_11}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_9603_softmax_cross_entropy_loss/value\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[16,224,54,54] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2_2a/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](relu1_2a, conv2_2a/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node softmax_cross_entropy_loss/value/_11}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_9603_softmax_cross_entropy_loss/value\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-257b7e4de8a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_resnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-d01846391362>\u001b[0m in \u001b[0;36mtrain_resnet\u001b[1;34m(training_examples, keys, learning_rate, num_epochs, batch_size, epoch_start, restore_path)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_cost\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m \u001b[0mmodel_input\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_training\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m             \u001b[0mepoch_cost\u001b[0m    \u001b[1;33m+=\u001b[0m \u001b[0mbatch_cost\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[16,224,54,54] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node conv2_2a/Conv2D (defined at <ipython-input-9-3da0f65c3867>:6)  = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](relu1_2a, conv2_2a/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node softmax_cross_entropy_loss/value/_11}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_9603_softmax_cross_entropy_loss/value\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'conv2_2a/Conv2D', defined at:\n  File \"c:\\program files (x86)\\microsoft visual studio\\shared\\anaconda3_64\\Lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\program files (x86)\\microsoft visual studio\\shared\\anaconda3_64\\Lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\program files (x86)\\microsoft visual studio\\shared\\anaconda3_64\\Lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"c:\\program files (x86)\\microsoft visual studio\\shared\\anaconda3_64\\Lib\\asyncio\\base_events.py\", line 1426, in _run_once\n    handle._run()\n  File \"c:\\program files (x86)\\microsoft visual studio\\shared\\anaconda3_64\\Lib\\asyncio\\events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-257b7e4de8a3>\", line 1, in <module>\n    train_resnet(training_set, keys)\n  File \"<ipython-input-12-d01846391362>\", line 9, in train_resnet\n    model, model_input, is_training = get_resnet_model(gpu=True)\n  File \"<ipython-input-10-483599925f48>\", line 19, in get_resnet_model\n    output = skip_connection(output, 224, \"2a\")\n  File \"<ipython-input-9-3da0f65c3867>\", line 6, in skip_connection\n    output = tf.layers.conv2d             (output     , filters=filters, kernel_size=(3, 3), padding='SAME', name=\"conv2_\" + layer)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\layers\\convolutional.py\", line 417, in conv2d\n    return layer.apply(inputs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 817, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 374, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 757, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\", line 194, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 868, in __call__\n    return self.conv_op(inp, filter)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 520, in __call__\n    return self.call(inp, filter)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 204, in __call__\n    name=self.name)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1044, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"c:\\deep_learning_workspace\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[16,224,54,54] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node conv2_2a/Conv2D (defined at <ipython-input-9-3da0f65c3867>:6)  = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](relu1_2a, conv2_2a/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node softmax_cross_entropy_loss/value/_11}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_9603_softmax_cross_entropy_loss/value\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "train_resnet(training_set, keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
