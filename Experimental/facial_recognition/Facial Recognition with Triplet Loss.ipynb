{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework import ops\n",
    "import imghdr\n",
    "import freeze_graph\n",
    "from tensorflow.python.tools import optimize_for_inference_lib\n",
    "from google.protobuf import text_format\n",
    "\n",
    "import os\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['essex-face-recognition-dataset.zip', 'faces94']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "3cf691062f21b4f0810b31d22522dbbaf333aa7e"
   },
   "outputs": [],
   "source": [
    "picture_paths = []\n",
    "labels        = []\n",
    "main_dir = '../data/faces94/'\n",
    "\n",
    "for sex_dir in os.listdir(main_dir):\n",
    "    for person_dir in os.listdir(main_dir + '/' + sex_dir):\n",
    "        for picture in os.listdir(main_dir + '/' + sex_dir + '/' + person_dir):\n",
    "            if imghdr.what(main_dir + '/' + sex_dir + '/' + person_dir + '/' + picture) == 'jpeg':\n",
    "                labels.append(person_dir)\n",
    "                picture_paths.append(main_dir + '/' + sex_dir + '/' + person_dir + '/' + picture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2793"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(picture_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "b889d10ce2db79a4eed42eaea4c32f19b1086891"
   },
   "outputs": [],
   "source": [
    "def _parse_function(filename, label):\n",
    "    image_string = tf.read_file(filename)\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    image_decoded = tf.reshape(image_decoded, [200*180*3])\n",
    "    image_resized = image_decoded/255\n",
    "    return image_resized, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "c050f68f6557195fb171f61f52ea970620f6c1a2"
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((picture_paths, labels))\n",
    "dataset = dataset.map(_parse_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "d24e3fe010b7e59b4aee965c62e46034d59ad62c"
   },
   "outputs": [],
   "source": [
    "#dataset = dataset.batch(800)\n",
    "#itr = dataset.make_one_shot_iterator()\n",
    "#next_itr = itr.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_uuid": "f747f21c8eefa5e9b412ac32fc944b407873ebf0"
   },
   "outputs": [],
   "source": [
    "#init = tf.global_variables_initializer()\n",
    "#with tf.Session() as sess:\n",
    "#    sess.run(init)\n",
    "#    for i in range(2):\n",
    "#        x,y = sess.run(next_itr)\n",
    "#        print(x.shape)\n",
    "#        fig = plt.figure(figsize=(5,5)); plt.axis('off')\n",
    "#        plt.imshow(x); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "7246851886bbf81959be7ff6c7b7b695f0e5a76e"
   },
   "outputs": [],
   "source": [
    "def create_placeholder(batch_size):\n",
    "    X = tf.placeholder(shape = [None, 200*180*3], dtype = 'float' , name = 'input_node')\n",
    "    Y = tf.placeholder(shape = [batch_size]     , dtype = 'string', name = 'Y'         )\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_uuid": "a3c749865a89d5744099a134b6c82d4b9a16368c"
   },
   "outputs": [],
   "source": [
    "def initialize_parameters():           \n",
    "    W1 = tf.get_variable('W1', [3, 3, 3, 6], initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "    W2 = tf.get_variable('W2', [3, 3, 6, 6], initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "    W3 = tf.get_variable('W3', [3, 3, 6, 6], initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "    \n",
    "    parameters = {'W1' : W1,\n",
    "                  'W2' : W2,\n",
    "                  'W3' : W3 }\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def first_layer_forward(X, parameters):\n",
    "    W1 = parameters['W1']\n",
    "    \n",
    "    X = tf.reshape(X, [-1, 200, 180, 3], name='X')\n",
    "    z = tf.nn.conv2d(X, W1, strides=[1,1,1,1], padding='SAME')\n",
    "    a = tf.nn.elu(z)\n",
    "    p = tf.nn.max_pool(a, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_uuid": "ea0401de127fa8de736c4547f42fe92f8a74e765"
   },
   "outputs": [],
   "source": [
    "def generic_skip_layer(p, parameters, num_layer):\n",
    "    W = parameters['W' + str(num_layer)]\n",
    "    \n",
    "    z = tf.nn.conv2d(p, W, strides = [1,1,1,1], padding='SAME')\n",
    "    a = tf.nn.elu(z)# + a_skip)\n",
    "    p = tf.nn.max_pool(a, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_uuid": "71753fd1d86a106c60f1f0b1a9068ef9c2314d1b"
   },
   "outputs": [],
   "source": [
    "def flatten_layer(p, keep_prob=True):\n",
    "    flat = tf.contrib.layers.flatten(p)\n",
    "    \n",
    "    dense    = tf.layers.dense(inputs=flat, units = 1024, activation=tf.nn.elu)\n",
    "    dropout  = tf.layers.dropout(inputs=dense, rate=0.4, training=keep_prob)\n",
    "    \n",
    "    return dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "35278b4746a474fdd027dc38e67dfef669cd211f"
   },
   "outputs": [],
   "source": [
    "def encoding_layer(dropout):\n",
    "    encoding = tf.contrib.layers.fully_connected(inputs=dropout, num_outputs=128, activation_fn=None)\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_my_graph(sess):    \n",
    "    input_graph_path            = './tmp/input_model/input_graph.pbtxt'\n",
    "    input_saver_def_path        = None\n",
    "    input_binary                = False\n",
    "    input_checkpoint_path       = './tmp/triplet_mode.ckpt'\n",
    "    output_node_names           = 'fully_connected/BiasAdd'\n",
    "    restore_op_name             = 'save/restore_all'\n",
    "    filename_tensor_name        = 'save/Const:0'\n",
    "    output_graph_path           = './tmp/input_model/output_graph.pb'\n",
    "    output_optimized_graph_name = './tmp/input_model/optimized_graph.pb'\n",
    "    clear_devices               = True\n",
    "    initializer_nodes           = ''\n",
    "    \n",
    "    freeze_graph.freeze_graph(input_graph_path     ,     \n",
    "                              input_saver_def_path , \n",
    "                              input_binary         ,         \n",
    "                              input_checkpoint_path,\n",
    "                              output_node_names    ,    \n",
    "                              restore_op_name      ,      \n",
    "                              filename_tensor_name , \n",
    "                              output_graph_path    ,    \n",
    "                              clear_devices        ,\n",
    "                              initializer_nodes    )\n",
    "    \n",
    "    gd = tf.GraphDef()\n",
    "    \n",
    "    with tf.gfile.Open(output_graph_path, 'rb') as f:\n",
    "        gd.ParseFromString(f.read())\n",
    "\n",
    "    output_graph_def = optimize_for_inference_lib.optimize_for_inference(\n",
    "        gd,\n",
    "        ['input_node'],\n",
    "        [output_node_names],\n",
    "        tf.float32.as_datatype_enum)\n",
    "    \n",
    "    with tf.gfile.FastGFile(output_optimized_graph_name, 'wb') as f:\n",
    "        f.write(output_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "_uuid": "e01bd6da3a413a95663384921cc4572dae5c7ca5"
   },
   "outputs": [],
   "source": [
    "def model_facenet(picture_paths, labels, learning_rate = 0.0001, num_epochs = 5, batch_size=32, margin=0.2):\n",
    "    ops.reset_default_graph()\n",
    "    m = 2796\n",
    "    #(m, n_h, n_w, n_c) = dataset.shape\n",
    "    encodings = []\n",
    "    costs     = []\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((picture_paths, labels))\n",
    "    dataset = dataset.map(_parse_function)\n",
    "    \n",
    "    test_dataset  = dataset.take(200)\n",
    "    train_dataset = dataset.skip(200)\n",
    "    \n",
    "    test_faces  = []\n",
    "    test_labels = []\n",
    "    test_itr    = test_dataset.make_one_shot_iterator()\n",
    "    next_test   = test_itr.get_next()\n",
    "    \n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    kp            = tf.placeholder(dtype='bool', name='kp')\n",
    "\n",
    "    init_itr  = train_dataset.make_initializable_iterator()\n",
    "    next_init = init_itr.get_next()\n",
    "\n",
    "    faceholder, labelholder = create_placeholder(batch_size)\n",
    "    parameters = initialize_parameters()\n",
    "    \n",
    "    #------LOOP FOR ANCHOR------#\n",
    "    first_hidden_layer = first_layer_forward(faceholder, parameters)\n",
    "    \n",
    "    pool = generic_skip_layer(first_hidden_layer, parameters,  2)\n",
    "    pool = generic_skip_layer(pool              , parameters,  3)\n",
    "\n",
    "    flat     = flatten_layer (pool, kp)\n",
    "    encoding = encoding_layer(flat)\n",
    "    \n",
    "    #------BACKPROPOGATION FOR WEIGHT UPDATES------#\n",
    "    cost      = tf.contrib.losses.metric_learning.triplet_semihard_loss(labels=labelholder, embeddings=encoding, margin=margin)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    #Saver for checkpointing model training & reloading\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        tf.train.write_graph(sess.graph.as_graph_def(), './tmp/input_model', 'input_graph.pbtxt', True)\n",
    "        for epoch in range(num_epochs):\n",
    "            sess.run(init_itr.initializer)\n",
    "            epoch_cost  = 0\n",
    "            num_batches = (int)((m-200) / batch_size)\n",
    "            for batch in range(num_batches):\n",
    "                faces, labels = sess.run(next_init)\n",
    "                _, batch_cost = sess.run([optimizer, cost], feed_dict = { faceholder : faces, labelholder : labels, kp : True})\n",
    "                epoch_cost += batch_cost / num_batches\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "                saver.save(sess, './tmp/triplet_mode.ckpt')\n",
    "        \n",
    "        for i in range(200):\n",
    "            test_x, test_y = sess.run(next_test)\n",
    "            test_faces .append(test_x)\n",
    "            test_labels.append(test_y)\n",
    "        \n",
    "        test_pred = sess.run(encoding, feed_dict={faceholder : test_faces, kp : False})\n",
    "        return test_pred, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "_uuid": "14bd34358dfbdb29338af52c37aff6f7c46ab34a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.049557\n"
     ]
    }
   ],
   "source": [
    "test_pred, test_labels =  model_facenet(picture_paths=picture_paths, labels=labels, num_epochs=1, margin=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tmp/triplet_mode.ckpt\n",
      "[[0.48627454 0.7411765  0.33333334 ... 1.         0.8588236  0.62352943]]\n"
     ]
    }
   ],
   "source": [
    "face  = tf.read_file('C:/facial_recognition/inputs/faces94/male/ambarw/ambarw.12.jpg')\n",
    "face = tf.image.decode_jpeg(face, channels=3)\n",
    "face = tf.reshape(face, [1, 200*180*3])\n",
    "face = face/255\n",
    "\n",
    "saver = tf.train.import_meta_graph('./tmp/triplet_mode.ckpt.meta')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './tmp/triplet_mode.ckpt')\n",
    "    n_face = face.eval()\n",
    "    print(n_face)\n",
    "    logits = sess.run('fully_connected/BiasAdd:0', feed_dict={'input_node:0' : n_face, 'kp:0': False})\n",
    "    \n",
    "    #freeze_my_graph(sess)        \n",
    "    #best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9571859296482412\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(200):\n",
    "    j = i + 1\n",
    "    while j < 200:\n",
    "        diff = np.linalg.norm(test_pred[i] - test_pred[j])\n",
    "        if (diff < 2.0 and test_labels[i] == test_labels[j]) or (diff >= 2.0 and test_labels[i] != test_labels[j]):\n",
    "            correct += 1\n",
    "            \n",
    "        j+=1\n",
    "print(correct/19900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
